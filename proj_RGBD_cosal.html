<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>RGBD Segmentation</title>

    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <meta name="viewport" content="width=device-width">
  </head>
  <body>
    <div class="wrapper">
<header>
<h7>Runmin Cong</h7><br><br>
<div>
<img src="sub_img/IMG11.jpg" border="0" width="80%"><br></div><br>

  
<p>
<small>runmincong@gmail.com rmcong@tju.edu.cn</small><br><br>
<a href="https://github.com/rmcong" target="_blank">[GitHub]</a>  
<a href="http://dblp.uni-trier.de/pers/hd/c/Cong:Runmin" target="_blank">[DBLP]</a>  <br>
<a href="https://scholar.google.co.uk/citations?hl=en&user=-VrKJ0EAAAAJ" target="_blank">[Google Scholar]</a> <br>
<a href="http://www.escience.cn/people/congrunmin/index.html" target="_blank">[e-Science]</a> 
</p> <br>
<p class="view"><a href="http://rmcong.github.io/">Homepage</a></p>
<p class="view"><a href="sub_publication.html">Publications</a></p>
<p class="view"><a href="sub_projects.html">Projects</a></p>
</header>

      <section>

<h2>
<a id="project_title" class="anchor" href="#project_title" aria-hidden="true"><span class="octicon octicon-link"></span></a>RGBD Co-saliency Detection</h2>




<h4>
<a id="Introduction-page" class="anchor" href="#Introduction-pages" aria-hidden="true"><span class="octicon octicon-link"></span></a>Introduction:</h4>

<p>Different from the most existing co-saliency methods focusing on RGB images, in this paper, we propose a novel co-saliency 
  detection model for RGBD images, which utilizes the depth information to enhance identification of co-saliency. In our method,
  the intra saliency map for each image is generated by the single image saliency model [1], while the multi-constraint feature
  matching is utilized to capture the constraint relationship among multiple images and produce the inter saliency map.
  Then, the optimization scheme, namely Cross Label Propagation (CLP), is used to update the intra and inter saliency maps in
  a cross way. Finally, all the original and optimized saliency maps are integrated to generate the final co-saliency result.
  The proposed method introduces the depth information and multi-constraint feature matching to improve the performance of
  co-saliency detection. Moreover, our proposed method can effectively exploit any existing single image saliency model to
  work well in co-saliency scenarios. Experiments on two RGBD co-saliency datasets demonstrate the efficiency of our proposed
  model.</p>

<div style="text-align: center; display: block; margin-right: auto;">
<img src="sub_img/rgbdcosal_1.png" border="0" width="600"><br></div><br>


<hr />
<h4>Paper:</h4>
    
<p>
  Runmin Cong, Jianjun Lei, Huazhu Fu, Qingming Huang, Xiaochun Cao, Chunping Hou, 
  <strong>Co-saliency detection for RGBD images based on multi-constraint feature matching and cross label propagation</strong>, 
  <em>IEEE Transactions on Image Processing</em>, 2017. <font color="#0000FF">DOI: 10.1109/TIP.2017.2763819.</font>
  <a href="https://arxiv.org/pdf/1710.05172.pdf"><font color="#ff0000">[arXiv]</font></a>
</p>

<hr />
<h4>RGBD Cosal150 Dataset:</h4>
<p>
  We construct a new RGBD co-saliency dataset, named RGBD Cosal150 dataset. In this dataset, we collected 21 image groups containing totally 
  150 images from RGBD NJU-1985 dataset [2] with pixel-level ground truth, and the original depth maps are provided by the dataset
  itself: <ud2>RGBD Cosal150 dataset (~13.9MB)</ud2> <a href="https://github.com/rmcong/RGBD-Cosal150-Dataset" target="_blank"><font color="#ff0000">[Download Link]</font></a>
</p>
<hr />
 
<hr />
<h4>RGBD Co-saliency Results:</h4>
<p>
  We evaluate the proposed co-saliency model on two datasets (RGBD Cosal150 dataset and RGBD Coseg183 dataset). Even though the images own complex 
  and variable backgrounds or the salient objects exhibit large variations in shape and direction, the proposed method effectively
  highlights the common salient objects from the image group. In addition, the proposed co-saliency model achieves the best
  performance on both of the RGBD Coal150 and Coseg183 datasets with the highest F-measure and the smallest MAE score: 
  <ud2>RGBD Co-saliency Results (~5.7MB)</ud2> <a href="https://github.com/rmcong/2017TIP-RGBD-Co-saliency-Results" target="_blank"><font color="#ff0000">[Download Link]</font></a>
</p>
<hr />
        
<h4>References:</h4>

<p>
  [1] R. Cong, J. Lei, C. Zhang, Q. Huang, X. Cao, C. Hou, "Saliency detection for stereoscopic images based on depth
  confidence analysis and multiple cues fusion," IEEE Signal Processing Letters, vol.23, no.6, pp.819-823, 2016.
  <a href="https://github.com/rmcong/Code-for-DCMC-method" target="_blank"><font color="#ff0000">[Code]</font></a><br/>
  [2] R. Ju, Y. Liu, T. Ren, L. Ge, and G. Wu, “Depth-aware salient object detection using anisotropic center-surround 
  difference,” Signal Process.: Image Commun., vol.38, pp.115-126, 2015. </p>
 



      </section>

    </div>
    <script src="../../javascripts/scale.fix.js"></script>
  </body>
</html>
